[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Data Wrangling And Visual",
    "section": "",
    "text": "Introduction\nHaving usable, clean data is essential part of the data science process. In this tutorial I will teach some basic data wrangling steps and teach how users how to create a few simple visuals for that data. This blog will help students and other users understand the importance of data wrangling as well as introduce them to simple data wrangling steps. I will be using data from the Los Angeles Lakers trying to answer the question of if home court advantage really helps teams win.\n\n\nImporting Data\nThe very first thing that we need to do in answering the question of if home court advantage really helps teams win is to get clean and usable data that will show us trends and help us come up with an answer. The data set that I found contains quite a bit of information, such as points scored, field goals made, and free throw percentage. However, in this tutorial we are not interested in those variables. As part of data wrangling we can make the data a whole lot cleaner simply by eliminating the variables that we are not interested in. When reading in data using the “pd.read_csv()” function we can use the built-in feature of “usecols =” to select the columns from the dataset that we are interested in. Here you can see that I selected to use the columns “MATCH UP”, “GAME DATE”, and “W/L”\n\n\nCode\nimport pandas as pd, json\n\ncols = [\"MATCH UP\", \"GAME DATE\", \"W/L\"]\ndata = pd.read_csv(\"Lakers2009-2021.csv\", usecols = cols)\nprint(data.head())\n\n\n      MATCH UP   GAME DATE W/L\n0    LAL @ NOP  05/16/2021   W\n1    LAL @ IND  05/15/2021   W\n2  LAL vs. HOU  05/12/2021   W\n3  LAL vs. NYK  05/11/2021   W\n4  LAL vs. PHX  05/09/2021   W\n\n\n\n\nData Wrangling\nAfter importing the data I need to do some data wrangling in order to do any anlysis towards the main question. I renamed the columns using the function “data.rename” for simplicity. After renaming the columns it was easier to run it through a function to seperate Home and Away games. To do this I created the “home_away” fuction which goes through the columns and if the designated string is in the value it assigns either “Home” or “Away”. I then applied this to the data and created a new column so that I can easily see whether the game was at home or if it was away.\n\n\nCode\ndata.rename(columns = {\n    'MATCH\\xa0UP' : 'Match_Up',\n    'GAME\\xa0DATE' : 'Game_Date'\n}, inplace=True)\n\ndef home_away(x):\n    x = x.strip().lower()\n    if \"vs.\" in x:\n        return \"Home\"\n    elif \"@\" in x: \n        return \"Away\"\n\ndata[\"Home/Away\"] = data[\"Match_Up\"].apply(home_away)\n\nprint(data.head())\n\n\n      Match_Up   Game_Date W/L Home/Away\n0    LAL @ NOP  05/16/2021   W      Away\n1    LAL @ IND  05/15/2021   W      Away\n2  LAL vs. HOU  05/12/2021   W      Home\n3  LAL vs. NYK  05/11/2021   W      Home\n4  LAL vs. PHX  05/09/2021   W      Home\n\n\n\n\nData Analysis and Visualization\nAfter doing some basic data wrangling, I did some simple data analysis and created a visual to help understand the data. Since I am interested in learning whether home court advantage exists for this basketball team I calculated the win percentages at both home and away. So we can see in the code output that the team wins at home 55 percent of the time and wins on the road 41 percent of the time. The visual that I created shows both the wins and losses at home and away so viewers can see the difference and compare. This visual helps us to see quickly that the team does win more games when playing at home and we can see that percentage that we just calculated.\n\n\nCode\nimport matplotlib.pyplot as plt\nhome_wins = data[(data['Home/Away'] == 'Home') & (data['W/L'] == 'W')]\nhome_total = data[data['Home/Away'] == 'Home']\nhome_win_pct = len(home_wins) / len(home_total)\nprint(home_win_pct)\n\naway_wins = data[(data['Home/Away'] == 'Away') & (data['W/L'] == 'W')]\naway_total = data[data['Home/Away'] == 'Away']\naway_win_pct = len(away_wins) / len(away_total)\nprint(away_win_pct)\n\n\nsummary = pd.crosstab(data['Home/Away'], data['W/L'])\nsummary.plot(kind='bar', figsize=(8,5), color=['lightcoral', 'mediumseagreen'])\nplt.title('Results for Home and Away Games')\nplt.xlabel(None)\nplt.ylabel('Number of Games')\n\n\n0.5539112050739958\n0.41139240506329117\n\n\nText(0, 0.5, 'Number of Games')\n\n\n\n\n\n\n\n\n\n\n\nConclusion and Call to Action\nAfter doing just some basic data wrangling, analysis and visualization we can see that the team does win more when they are playing at home, however just with this basic level of anaysis we cannot make any strong conclusions that playing at home will lead to more wins than playing away. In order to form that conclusion we would need to do a more in depth analysis. The main takeaway for readers should be that there are simple ways to import, clean, analyze and visualize data that can be done with a few simple functions and packages. People interested in data can apply this same process by following the steps and even utalizing some of the code shown here to help them understand the data that they are working on.",
    "crumbs": [
      "Home",
      "Data Wrangling And Visual"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\n\nHome Page\n\nIntroduction\nHi! My name is Sam Kirkham, I am a statistics major at BYU! A few things about me: I am from Kaysville Ut, I love the outdoors, and I love anything and everything sports. I love watching basketball and football and love working on data for both of these sports as well.\nTwo things I have loved learning about are data cleaning and visualization. In this blog I want to share an example as I teach a little bit about this process using sports data. In this example I am looking at the Los Angeles Lakers and whether playing at home or on the road impacts the results of their games. I hope you enjoy!",
    "crumbs": [
      "Home",
      "Home Page"
    ]
  },
  {
    "objectID": "DataAcquisation.html",
    "href": "DataAcquisation.html",
    "title": "Introduction",
    "section": "",
    "text": "With the success that the BYU football team has had this season it is interesting that they have been betting underdogs for a quite a few games this season, including this last week against Iowa State, a team that had already lost two games this season. So when the betting line came out that BYU is a 10.5 point underdog for this week’s game against Texas Tech I was shocked that it was such a large line. Recently I heard a theory that the lines are skewed in an effort to bring more bettors to the game because a majority of BYU fans do not gamble. So I was interested in looking into this question and seeing what I could learn about BYU betting lines from the last few seasons. My hope from this project is to learn as a fan of BYU, if there is any credit to the skewed betting lines or if I should ignore them as they are soley an effort to bring more money to bets on BYU games.\n\nMotivating Question\nThe question that I came up with is, what factors are good predictors for if BYU will cover the line that is set by odds makers. What this looks like is are there factors, like BYU is playing at home this weekend, or does the total number of points scored relate to BYU covering the spread given. I also have other factors such as BYU’s point differential as well as the starting spread from odds makers.\n\n\nEthical Data Acquisition\nI found data for my question of interest on collegefootballdata.com. As I was looking at the datasets that they had available I saw they had a lot of good data for any college football team that I wanted and found the data for BYU. After finding the data that I wanted I looked at their terms and conditions to learn more about getting data from them. The data was in a format that allowed for easy downloading without signing up for anything, which was a sign that getting data from them was okay. They did have an option to sign up for an API key to get data from them as well and after looking into that further I never saw a place where using the API key was the only way to get the data. There was no mention of any restrictions in data usage.\n\n\nSummary of Getting Data\nFrom collegefootball.com I was ale to get data for betting lines per season. In order to get enough data to come to some conclusions I grabbed data from the 2020 season through the games that have been played so far in the 2025 season. Each season’s data came as a .csv file so getting the data was not difficult as it just required downloading each file and then reading them in using pd.read_csv. In order to create a data set that included all of these seasons I had to use pd.concat. After doing that I had a nice data set that included all the data. If someone wanted to follow a similar path of combining .csv files together to make a data set I think that pd.concat is the easiest way as it will take the columns that are included in the individual sets and all of those columns will be included in the final data set, any missing data will be filled in with NaNs.\nFor my question of interest I wanted to extract some data that was already included in the data and add additional columns that would help with the analysis. Most of these new columns were simple as they were things like adding two of the original columns or creating boolean statements that would create columns that are true or false values. After creating these columns of interest I dropped any columns that I will not be using to ensure that my data is neat and clean. These are simple steps that can be done to any dataset that allows for a more in depth analysis.\n\n\nEDA Highlights\n\n\nCode\nimport pandas as pd, json\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\n\ndata = pd.read_csv('BettingLinesFinal.csv')\ndata.head()\n\nlen(data)\n\n\n251\n\n\nYou can see that I have 251 observations. These come from the games that BYU has played in the last 6 seasons.\n\n\nCode\ndata.describe()\n\n\n\n\n\n\n\n\n\nHomeScore\nAwayScore\nOverUnder\nYear\nNormalizedSpread\nBYU_Diff\nTotalScore\nOver/Under\n\n\n\n\ncount\n251.000000\n251.000000\n249.000000\n251.000000\n251.000000\n251.000000\n251.000000\n249.000000\n\n\nmean\n30.247012\n25.163347\n54.871486\n2022.027888\n6.500000\n9.553785\n55.410359\n0.481928\n\n\nstd\n12.679540\n12.707526\n7.296676\n1.618400\n13.569598\n19.143670\n14.571580\n13.308857\n\n\nmin\n3.000000\n0.000000\n39.500000\n2020.000000\n-24.500000\n-33.000000\n14.000000\n-36.500000\n\n\n25%\n21.500000\n17.000000\n49.500000\n2021.000000\n-3.500000\n-3.000000\n45.500000\n-7.000000\n\n\n50%\n28.000000\n24.000000\n54.500000\n2022.000000\n3.500000\n9.000000\n55.000000\n0.500000\n\n\n75%\n38.000000\n34.000000\n60.000000\n2023.000000\n14.500000\n20.000000\n62.000000\n8.500000\n\n\nmax\n69.000000\n55.000000\n80.000000\n2025.000000\n50.000000\n69.000000\n115.000000\n49.000000\n\n\n\n\n\n\n\nJust some basic summary statistics from the data set.\n\n\nCode\nsns.countplot(data = data, x = 'Year', hue = 'Cover')\nplt.show()\n\n\n\n\n\n\n\n\n\nThis plot shows the number of spreads that BYU has covered for each of the last 6 football seasons. From this graph you can clearly see the years that BYU football has had the most success.\n\n\nCode\nbyu_underdog = data[data['NormalizedSpread'] &lt; 0]\nbyu_underdog_25 = byu_underdog[byu_underdog['Year'].isin([2024, 2025])]\nnum_underdog_covered = byu_underdog_25['Cover'].sum()\n\nprint(f\"BYU was an underdog in {len(byu_underdog_25)} games.\")\nprint(f\"BYU covered the spread in {num_underdog_covered} of those games.\")\n\n\nBYU was an underdog in 24 games.\nBYU covered the spread in 21 of those games.\n\n\nI was especially interested in the last 2 BYU football seasons so I looked, got just the data for that and found the games where BYU was expected to lose. Here are the results.\nLinks to Resources:\nLink for the data\nLink for more code",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\n\nAbout Me\n\n\n\nPicture of Me\n\n\n\nEducation\n\nBrigham Young University\n\nMajoring in Applied Statistics\nProjected Graduation April 2026\n\nRelevant Course Work\n\nData Science Process\nPredictive Analytics\nApplied R Programming\nSpreadsheets and Business Analysis\n\n\n\n\nExperience\n\nTeacher, Missionary Training Center\n\nEducate young adults in teaching skills\nLead groups of 10 - 14 young adults in practices of new skills\n\nCounselor, For the Strength of Youth\n\nLead groups of 14 - 18 youth in summer camp activities\nTeach short lessons to small groups\n\nProjects\n\nAmazon Acess\n\nI am currently working on different models to see how accurately I can predict who gets access in Amazon’s system\n\nNBA 2024 Draft Picks\n\nI did some initial EDA and modeling to notice any trends in player stats that would help predict which players would be drafted\n\n\n\n\n\nSkills\n\nCoding Languages\n\nR\nPython\n\nOther Skills\n\nExcel Spreadsheets\nCommunication\nTeaching\n\n\n\n\nGet to Know Me\nI love anything and everything outdoors. One of my favorite hobbies is disc golf, I love that it gets me outdoors and into the mountains. I also love soccer, I have played soccer since I was a little kid. I’ve never played in high school or college, I’ve only ever played for fun in recreation leagues and competitive leagues. Just some small fun facts about me: I served a mission for the Church of Jesus Christ of Latter-Day Saints in Atlanta Georgia, I love Dr. Pepper and despite going to BYU my favorite college football team is the Georgia Football team.",
    "crumbs": [
      "Home",
      "About Me"
    ]
  }
]